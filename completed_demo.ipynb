{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "# handle warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset from csv file\n",
    "df = pd.read_csv('flights_dataset.csv')\n",
    "\n",
    "# Can also use .read_excel(). To use read_excel, it requires openpyxl (make sure you have it installed)\n",
    "# df = pd.read_excel('flights_dataset.xlsx') # uncomment if you want to use read_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the data (first 5 rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inspection (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the columns in dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect info about dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rows and columns (shape)\n",
    "df.shape # ( # rows, # columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with NaN values\n",
    "# df = df.dropna() # uncomment if you want to use re-assignment\n",
    "df.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect info about dataframe again\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata (day, month, day_of_week) from the column \"Date_of_Journey\"\n",
    "df[\"Journey_day\"] = pd.to_datetime(df.Date_of_Journey, format=\"%d/%m/%Y\").dt.day\n",
    "df[\"Journey_month\"] = pd.to_datetime(df.Date_of_Journey, format=\"%d/%m/%Y\").dt.month\n",
    "df[\"Journey_dow\"] = pd.to_datetime(df.Date_of_Journey, format=\"%d/%m/%Y\").dt.day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demo on how `to_datetime` works\n",
    "demo_date = pd.to_datetime(\"31/08/1957\", format=\"%d/%m/%Y\")\n",
    "\n",
    "demo_date.day # day of month \n",
    "demo_date.month # month     \n",
    "demo_date.year # year\n",
    "demo_date.day_of_week # Monday is 0, Sunday is 6\n",
    "demo_date.day_name() # day of week (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column Date_of_Journey\n",
    "df.drop(columns=[\"Date_of_Journey\"], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to Date_of_Journey we can extract values (hour, minute) from Dep_Time\n",
    "\n",
    "# Extracting Hours\n",
    "df[\"Dep_hour\"] = pd.to_datetime(df[\"Dep_Time\"]).dt.hour\n",
    "df[\"Dep_min\"] = pd.to_datetime(df[\"Dep_Time\"]).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Dep Time column\n",
    "df.drop(columns=[\"Dep_Time\"], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect current dataframe with .head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to convert the Dep_Time column to minutes\n",
    "def convert_duration_to_minute(duration_string):\n",
    "    \"\"\"\n",
    "    Converts a duration string to minutes\n",
    "    \"\"\"\n",
    "    if duration_string == \"\":\n",
    "        return 0\n",
    "    else:\n",
    "        duration_list = duration_string.split(\" \") # split the string by space [ \"1h\", \"30m\" ]\n",
    "\n",
    "        if len(duration_list) != 2: \n",
    "            duration_list.append(\"0m\") if \"h\" in duration_list[0] else duration_list.insert(0, \"0h\")\n",
    "\n",
    "        hours = int(duration_list[0].split(\"h\")[0])\n",
    "        minutes = int(duration_list[1].split(\"m\")[0])\n",
    "\n",
    "        return hours*60 + minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit tests to ensure the function works\n",
    "assert convert_duration_to_minute(\"2h 30m\") == 150\n",
    "assert convert_duration_to_minute(\"1h 30m\") == 90\n",
    "assert convert_duration_to_minute(\"1h\") == 60   \n",
    "assert convert_duration_to_minute(\"30m\") == 30\n",
    "assert convert_duration_to_minute(\"\") == 0 \n",
    "\n",
    "# assert convert_duration_to_minute(\"1h 30m\") == 60 # False assertion (uncomment to see error raised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the column Dep_Time to minutes (new column Duration_min)\n",
    "df[\"Duration_min\"] = df[\"Duration\"].apply(convert_duration_to_minute) # using .apply\n",
    "\n",
    "# list comprehension\n",
    "# df[\"Duration_min\"] = [ convert_duration_to_minute(duration) for duration in df[\"Duration\"] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Duration column\n",
    "df.drop(columns=[\"Duration\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of occurences of each airline\n",
    "df.Airline.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick plot price distribution for each airline \n",
    "sns.boxplot(x=\"Airline\", y=\"Price\", data=df.sort_values(by='Price', ascending=False)) # boxplot of Price by Airline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Airline to dummy variables (OnehotEncoding)\n",
    "airlines=  pd.get_dummies(df.Airline, prefix= \"Airline\", drop_first= True) \n",
    "airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine count of each \"Source\"\n",
    "df.Source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of price by Source\n",
    "sns.boxplot(x=\"Source\", y=\"Price\", data=df.sort_values(by='Price', ascending=False)) # boxplot of Price by Source\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Source to dummy variables\n",
    "source = pd.get_dummies(df.Source , prefix=\"Source\", drop_first= True)\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Destination to dummy variables\n",
    "destination = pd.get_dummies(df.Destination , prefix=\"Dest\", drop_first= True)\n",
    "destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect Additional_info from dataframe \n",
    "df.Additional_Info.value_counts() \n",
    "\n",
    "# we observed majority of Additional_Info is 'No info'\n",
    "# Route is also too complicated to be useful (correlated to TOTAL_STOPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns \"Airline\", \"Source\", \"Destination\", \"Additional_Info\", \"Route\"\n",
    "df.drop(columns=[\"Airline\", \"Source\", \"Destination\", \"Additional_Info\", \"Route\"], inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out sample values (unique) in Total_Stops\n",
    "df.Total_Stops.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .map to convert Total_Stops to count of stops (int) - N_stop\n",
    "# mapping used: {\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}\n",
    "\n",
    "df[\"N_stop\"] = df.Total_Stops.map({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns \"Total_Stops\", \"Arrival_Time\"\n",
    "df.drop(columns=[\"Total_Stops\", \"Arrival_Time\"], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the dataframes (df , airlines, source, destination)\n",
    "data = pd.concat([df, airlines, source, destination], axis=1) \n",
    "\n",
    "# and check out the dataframe\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows us to see more information regarding the DataFrame\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers (Subjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot on target variable- Price\n",
    "sns.boxplot(x =\"Price\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if price > 40k, then assign to median price\n",
    "price_median = data.Price.median()\n",
    "\n",
    "# using list comprehension to assign median price to all prices > 40k\n",
    "data[\"Target\"] = [ price_median  if price >= 40000 else price for price in data.Price ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for Target column (expected to see now more values > 40k )\n",
    "sns.boxplot(x =\"Target\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Price column\n",
    "data.drop(columns=[\"Price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Write dataframe into a csv file\n",
    "data.to_csv(\"clean_data.csv\", index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test \n",
    "# test_size: proportion of data to be used for testing\n",
    "# random_state: seed for random number generator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=[\"Target\"]), data[\"Target\"], test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate the model and fit the model\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train) # train model\n",
    "\n",
    "training_score = linear_reg.score(X_train, y_train) # 0.6113\n",
    "print(\"Training Score: \", training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "r2score = r2_score(y_test, y_pred) \n",
    "\n",
    "print(\"R2 Score: \", r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print('MAE: {}'.format(mean_absolute_error(y_test, y_pred)))\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, y_pred)))\n",
    "print('RSME: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into a function with model as input \n",
    "def train_and_predict(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train and predict using a given  model\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Model: \", model)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Training Score: \", model.score(X_train, y_train))\n",
    "\n",
    "    # predict on test data and it's metrics\n",
    "    predict_with_metrics(model, X_test, y_test)\n",
    "\n",
    "\n",
    "def predict_with_metrics(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Predict on test data and print metrics\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2score = r2_score(y_test, y_pred)\n",
    "    print(\"R2 Score: \", r2score)\n",
    "\n",
    "    print('MAE: {}'.format(mean_absolute_error(y_test, y_pred)))\n",
    "    print('MSE: {}'.format(mean_squared_error(y_test, y_pred)))\n",
    "    print('RSME: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg_rf = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "train_and_predict(reg_rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "feat_importance = pd.Series(reg_rf.feature_importances_ , index = X_train.columns)\n",
    "\n",
    "feat_importance.nlargest(20).plot(kind= 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost Regressor \n",
    "from xgboost import XGBRegressor\n",
    "xgboost_model = XGBRegressor(n_estimators=100, random_state=123)\n",
    "\n",
    "train_and_predict(xgboost_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance (with xgboost)\n",
    "from xgboost import plot_importance \n",
    "\n",
    "plot_importance(xgboost_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Generally there's two types of hyperparameter tuning methods: \n",
    "- RandomizedSearchCV (Faster)\n",
    "- GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "param_grid= {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'subsample': [ 0.5, 0.75 , 0.9] , \n",
    "    'colsample_bytree': [ 0.5, 0.75, 0.9 ] ,\n",
    "}\n",
    "\n",
    "# estimator : The estimator being fit, here, it's the XGBoost\n",
    "# param_distribution : distributoon of the possible hyper-param\n",
    "# cv : number of cross-validation. iteration\n",
    "# n_iter : number of hyperparam combination to choose from\n",
    "# verbose: (2) print more output \n",
    "\n",
    "xgb_model_tuned = RandomizedSearchCV(estimator=xgboost_model, param_distributions=param_grid, n_iter= 10, cv=3, verbose=2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data (with hyperparameters)\n",
    "xgb_model_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view best param based on the combination above\n",
    "xgb_model_tuned.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data and it's metrics\n",
    "predict_with_metrics(xgb_model_tuned, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b94be064a017ef4ea55ea8ebf8455ec65dd8bda815a5ca919074ccd68019a4b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('flight-fare')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
